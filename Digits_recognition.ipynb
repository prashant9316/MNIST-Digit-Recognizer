{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digits recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashant9316/MNIST-Digit-Recognizer/blob/master/Digits_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njkvHYoPt4CH",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "67a25c69-cd02-4cf5-d158-46ef909b4f56"
      },
      "source": [
        "# Uploading the datasets for MNIST \n",
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1dbc6b25-2dcd-4b3f-ac6f-1e7eca865eff\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1dbc6b25-2dcd-4b3f-ac6f-1e7eca865eff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading train.csv to /content\n",
            " 81% 59.0M/73.2M [00:01<00:00, 32.6MB/s]\n",
            "100% 73.2M/73.2M [00:01<00:00, 44.7MB/s]\n",
            "Downloading test.csv to /content\n",
            " 84% 41.0M/48.8M [00:00<00:00, 59.6MB/s]\n",
            "100% 48.8M/48.8M [00:00<00:00, 110MB/s] \n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 76.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDZ6XDz2uCVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khw5mBQ4vJ5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZxal9WnvSY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "368f1982-1b1e-4e89-fd4f-a83b2a7e0d75"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL1wtSvFvnW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting into training and validation set\n",
        "X_features = train.iloc[:,1:785].values\n",
        "y_prediction = train.iloc[:,0].values\n",
        "\n",
        "X_test_features = test.iloc[:,0:784].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dN3e3Jv4BN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features,\n",
        "                                                    y_prediction,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 101)\n",
        "\n",
        "np.random.seed(101)\n",
        "\n",
        "X_train = X_train.reshape(33600, 784) #(33600, 784)\n",
        "X_test = X_test.reshape(8400, 784) #(8400, 784)\n",
        "\n",
        "X_test_features = X_test_features.reshape(28000, 784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbcZcBp0wJ5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "979ac7b5-a734-43d9-b974-4dede63f0762"
      },
      "source": [
        "print(X_test_features.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m17DTUg0dQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating our model\n",
        "n_input = 784 # number of features\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 100\n",
        "n_hidden_3 = 100\n",
        "n_hidden_4 = 200\n",
        "num_digits = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpXmKegY2TU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK1O3R8q2g44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(Inp, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkAUlIY-xPaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "X_train = X_train.astype('float32'); X_test= X_test.astype('float32'); X_test_features = X_test_features.astype('float32')\n",
        "X_train /= 255; X_test /= 255; X_test_features /= 255\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_9SrtsF2ex7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ee95cf46-d3bc-4843-823f-9f746d5b0010"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 297,910\n",
            "Trainable params: 297,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AS5aK2r2u2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "sgd = optimizers.SGD(lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R__uUyW3Io0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwoS7CbB33iD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "eb984326-0623-4544-99db-7c0dd4840635"
      },
      "source": [
        "history1 = model.fit(X_train, y_train,\n",
        "                     batch_size = batch_size,\n",
        "                     epochs = training_epochs,\n",
        "                     verbose = 2,\n",
        "                     validation_data=(X_test, y_test))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            " - 2s - loss: 1.7766 - acc: 0.5161 - val_loss: 0.8926 - val_acc: 0.7926\n",
            "Epoch 2/20\n",
            " - 2s - loss: 0.5947 - acc: 0.8428 - val_loss: 0.4442 - val_acc: 0.8724\n",
            "Epoch 3/20\n",
            " - 2s - loss: 0.3920 - acc: 0.8890 - val_loss: 0.3516 - val_acc: 0.8983\n",
            "Epoch 4/20\n",
            " - 2s - loss: 0.3262 - acc: 0.9065 - val_loss: 0.3052 - val_acc: 0.9115\n",
            "Epoch 5/20\n",
            " - 2s - loss: 0.2911 - acc: 0.9160 - val_loss: 0.2786 - val_acc: 0.9176\n",
            "Epoch 6/20\n",
            " - 2s - loss: 0.2638 - acc: 0.9231 - val_loss: 0.2611 - val_acc: 0.9210\n",
            "Epoch 7/20\n",
            " - 2s - loss: 0.2427 - acc: 0.9289 - val_loss: 0.2473 - val_acc: 0.9263\n",
            "Epoch 8/20\n",
            " - 2s - loss: 0.2251 - acc: 0.9338 - val_loss: 0.2236 - val_acc: 0.9338\n",
            "Epoch 9/20\n",
            " - 2s - loss: 0.2100 - acc: 0.9385 - val_loss: 0.2126 - val_acc: 0.9377\n",
            "Epoch 10/20\n",
            " - 2s - loss: 0.1976 - acc: 0.9420 - val_loss: 0.2019 - val_acc: 0.9404\n",
            "Epoch 11/20\n",
            " - 2s - loss: 0.1859 - acc: 0.9455 - val_loss: 0.1925 - val_acc: 0.9433\n",
            "Epoch 12/20\n",
            " - 2s - loss: 0.1746 - acc: 0.9498 - val_loss: 0.1878 - val_acc: 0.9450\n",
            "Epoch 13/20\n",
            " - 2s - loss: 0.1652 - acc: 0.9521 - val_loss: 0.1795 - val_acc: 0.9456\n",
            "Epoch 14/20\n",
            " - 2s - loss: 0.1561 - acc: 0.9552 - val_loss: 0.1694 - val_acc: 0.9520\n",
            "Epoch 15/20\n",
            " - 2s - loss: 0.1477 - acc: 0.9572 - val_loss: 0.1646 - val_acc: 0.9524\n",
            "Epoch 16/20\n",
            " - 2s - loss: 0.1406 - acc: 0.9599 - val_loss: 0.1561 - val_acc: 0.9544\n",
            "Epoch 17/20\n",
            " - 2s - loss: 0.1336 - acc: 0.9618 - val_loss: 0.1571 - val_acc: 0.9535\n",
            "Epoch 18/20\n",
            " - 2s - loss: 0.1266 - acc: 0.9638 - val_loss: 0.1475 - val_acc: 0.9569\n",
            "Epoch 19/20\n",
            " - 2s - loss: 0.1209 - acc: 0.9650 - val_loss: 0.1451 - val_acc: 0.9564\n",
            "Epoch 20/20\n",
            " - 2s - loss: 0.1152 - acc: 0.9669 - val_loss: 0.1367 - val_acc: 0.9599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqKsFDdu5GTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To Increase the accuracy of the model, I am now going to use the adam optimizer\n",
        "# Creating another model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_x4rOPZ7Mbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
        "\n",
        "# We rely on ADAM as our optimizing methodology\n",
        "adam = keras.optimizers.Adam(lr=learning_rate)\n",
        "model2 = Model(Inp, output)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScStwqFC7U2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "b95aa070-9234-40fd-986e-d49c74cccf59"
      },
      "source": [
        "history2 = model2.fit(X_train, y_train,\n",
        "                      batch_size = batch_size,\n",
        "                      epochs = training_epochs,\n",
        "                      verbose = 2,\n",
        "                      validation_data=(X_test, y_test))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            " - 3s - loss: 0.3339 - acc: 0.8988 - val_loss: 0.1617 - val_acc: 0.9526\n",
            "Epoch 2/20\n",
            " - 2s - loss: 0.1206 - acc: 0.9632 - val_loss: 0.1345 - val_acc: 0.9589\n",
            "Epoch 3/20\n",
            " - 2s - loss: 0.0779 - acc: 0.9756 - val_loss: 0.1042 - val_acc: 0.9681\n",
            "Epoch 4/20\n",
            " - 2s - loss: 0.0578 - acc: 0.9818 - val_loss: 0.0995 - val_acc: 0.9719\n",
            "Epoch 5/20\n",
            " - 2s - loss: 0.0429 - acc: 0.9855 - val_loss: 0.1160 - val_acc: 0.9679\n",
            "Epoch 6/20\n",
            " - 2s - loss: 0.0354 - acc: 0.9889 - val_loss: 0.1152 - val_acc: 0.9696\n",
            "Epoch 7/20\n",
            " - 2s - loss: 0.0296 - acc: 0.9899 - val_loss: 0.0988 - val_acc: 0.9727\n",
            "Epoch 8/20\n",
            " - 2s - loss: 0.0255 - acc: 0.9911 - val_loss: 0.0958 - val_acc: 0.9756\n",
            "Epoch 9/20\n",
            " - 2s - loss: 0.0209 - acc: 0.9932 - val_loss: 0.1017 - val_acc: 0.9730\n",
            "Epoch 10/20\n",
            " - 2s - loss: 0.0176 - acc: 0.9940 - val_loss: 0.1195 - val_acc: 0.9727\n",
            "Epoch 11/20\n",
            " - 2s - loss: 0.0180 - acc: 0.9936 - val_loss: 0.1230 - val_acc: 0.9744\n",
            "Epoch 12/20\n",
            " - 2s - loss: 0.0167 - acc: 0.9948 - val_loss: 0.1149 - val_acc: 0.9740\n",
            "Epoch 13/20\n",
            " - 2s - loss: 0.0149 - acc: 0.9957 - val_loss: 0.1057 - val_acc: 0.9754\n",
            "Epoch 14/20\n",
            " - 2s - loss: 0.0159 - acc: 0.9951 - val_loss: 0.1088 - val_acc: 0.9743\n",
            "Epoch 15/20\n",
            " - 2s - loss: 0.0138 - acc: 0.9955 - val_loss: 0.1101 - val_acc: 0.9739\n",
            "Epoch 16/20\n",
            " - 2s - loss: 0.0153 - acc: 0.9950 - val_loss: 0.1186 - val_acc: 0.9739\n",
            "Epoch 17/20\n",
            " - 2s - loss: 0.0111 - acc: 0.9965 - val_loss: 0.1126 - val_acc: 0.9757\n",
            "Epoch 18/20\n",
            " - 2s - loss: 0.0136 - acc: 0.9960 - val_loss: 0.1191 - val_acc: 0.9736\n",
            "Epoch 19/20\n",
            " - 2s - loss: 0.0126 - acc: 0.9961 - val_loss: 0.1154 - val_acc: 0.9760\n",
            "Epoch 20/20\n",
            " - 2s - loss: 0.0108 - acc: 0.9970 - val_loss: 0.1255 - val_acc: 0.9755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "effT7ywI7eGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a 7 layer deep learning model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdUxv9wn8YW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784 # number of features\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 100\n",
        "n_hidden_3 = 100\n",
        "n_hidden_4 = 100\n",
        "n_hidden_5 = 200\n",
        "num_digits = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQJCYyTV8ab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce4WMtrZ8c92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f0fd336f-02d8-497b-a9cd-58d992453979"
      },
      "source": [
        "mode3 = Model(Inp, output)\n",
        "mode3.summary()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_4 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_5 (Dense)       (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 308,010\n",
            "Trainable params: 308,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sG7DUzE8geL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = keras.optimizers.Adam(lr=0.01)\n",
        "\n",
        "mode3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o4PfSMI8qGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "f39e5d60-420c-4940-f2c8-2705ce14ba35"
      },
      "source": [
        "history3 = mode3.fit(X_train, y_train,\n",
        "                      batch_size = batch_size,\n",
        "                      epochs = training_epochs,\n",
        "                      validation_data=(X_test, y_test))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            "33600/33600 [==============================] - 3s 89us/step - loss: 0.3538 - acc: 0.8917 - val_loss: 0.1707 - val_acc: 0.9469\n",
            "Epoch 2/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.1283 - acc: 0.9610 - val_loss: 0.1143 - val_acc: 0.9662\n",
            "Epoch 3/20\n",
            "33600/33600 [==============================] - 2s 72us/step - loss: 0.0839 - acc: 0.9737 - val_loss: 0.1192 - val_acc: 0.9651\n",
            "Epoch 4/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.0625 - acc: 0.9798 - val_loss: 0.1070 - val_acc: 0.9661\n",
            "Epoch 5/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0493 - acc: 0.9839 - val_loss: 0.0907 - val_acc: 0.9740\n",
            "Epoch 6/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0407 - acc: 0.9863 - val_loss: 0.0926 - val_acc: 0.9746\n",
            "Epoch 7/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0380 - acc: 0.9874 - val_loss: 0.1022 - val_acc: 0.9737\n",
            "Epoch 8/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0281 - acc: 0.9905 - val_loss: 0.1180 - val_acc: 0.9720\n",
            "Epoch 9/20\n",
            "33600/33600 [==============================] - 2s 72us/step - loss: 0.0253 - acc: 0.9923 - val_loss: 0.0961 - val_acc: 0.9732\n",
            "Epoch 10/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.1482 - val_acc: 0.9680\n",
            "Epoch 11/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0259 - acc: 0.9915 - val_loss: 0.1224 - val_acc: 0.9712\n",
            "Epoch 12/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0276 - acc: 0.9915 - val_loss: 0.1021 - val_acc: 0.9774\n",
            "Epoch 13/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0207 - acc: 0.9940 - val_loss: 0.1084 - val_acc: 0.9742\n",
            "Epoch 14/20\n",
            "33600/33600 [==============================] - 2s 74us/step - loss: 0.0152 - acc: 0.9951 - val_loss: 0.1250 - val_acc: 0.9725\n",
            "Epoch 15/20\n",
            "33600/33600 [==============================] - 3s 76us/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.1040 - val_acc: 0.9775\n",
            "Epoch 16/20\n",
            "33600/33600 [==============================] - 2s 74us/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.1109 - val_acc: 0.9769\n",
            "Epoch 17/20\n",
            "33600/33600 [==============================] - 2s 74us/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.1144 - val_acc: 0.9748\n",
            "Epoch 18/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.1184 - val_acc: 0.9752\n",
            "Epoch 19/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.1137 - val_acc: 0.9761\n",
            "Epoch 20/20\n",
            "33600/33600 [==============================] - 2s 73us/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.1326 - val_acc: 0.9708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKg5nD6q8zgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating another model with dropout to prevent overfitting of model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVZFw9se9The",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784 # number of features\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 100\n",
        "n_hidden_3 = 100\n",
        "n_hidden_4 = 200\n",
        "num_digits = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m5mS4069YsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a6b4fcdf-5581-419f-96a6-8385fbb51495"
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfIz9V9B9bI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "926d895d-d31e-4981-d13a-492a32cd77e6"
      },
      "source": [
        "model4 = Model(Inp, output)\n",
        "model4.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 297,910\n",
            "Trainable params: 297,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASxLeB_29eBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTlXUala9pIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "f0cf2bc8-6317-4739-a4c5-aebaa5b3a668"
      },
      "source": [
        "history4 = model4.fit(X_train, y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = training_epochs,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            "33600/33600 [==============================] - 3s 93us/step - loss: 0.5935 - acc: 0.8072 - val_loss: 0.1805 - val_acc: 0.9469\n",
            "Epoch 2/20\n",
            "33600/33600 [==============================] - 3s 74us/step - loss: 0.2265 - acc: 0.9332 - val_loss: 0.1325 - val_acc: 0.9608\n",
            "Epoch 3/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.1765 - acc: 0.9484 - val_loss: 0.1106 - val_acc: 0.9665\n",
            "Epoch 4/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.1406 - acc: 0.9577 - val_loss: 0.0955 - val_acc: 0.9721\n",
            "Epoch 5/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.1231 - acc: 0.9633 - val_loss: 0.0924 - val_acc: 0.9736\n",
            "Epoch 6/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.1099 - acc: 0.9678 - val_loss: 0.0941 - val_acc: 0.9733\n",
            "Epoch 7/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.0970 - acc: 0.9706 - val_loss: 0.0995 - val_acc: 0.9745\n",
            "Epoch 8/20\n",
            "33600/33600 [==============================] - 2s 74us/step - loss: 0.0926 - acc: 0.9724 - val_loss: 0.0883 - val_acc: 0.9732\n",
            "Epoch 9/20\n",
            "33600/33600 [==============================] - 3s 76us/step - loss: 0.0837 - acc: 0.9747 - val_loss: 0.0920 - val_acc: 0.9746\n",
            "Epoch 10/20\n",
            "33600/33600 [==============================] - 3s 76us/step - loss: 0.0735 - acc: 0.9779 - val_loss: 0.0884 - val_acc: 0.9775\n",
            "Epoch 11/20\n",
            "33600/33600 [==============================] - 3s 76us/step - loss: 0.0736 - acc: 0.9779 - val_loss: 0.0902 - val_acc: 0.9768\n",
            "Epoch 12/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.0658 - acc: 0.9806 - val_loss: 0.0993 - val_acc: 0.9735\n",
            "Epoch 13/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.0651 - acc: 0.9808 - val_loss: 0.0852 - val_acc: 0.9789\n",
            "Epoch 14/20\n",
            "33600/33600 [==============================] - 3s 76us/step - loss: 0.0579 - acc: 0.9824 - val_loss: 0.0834 - val_acc: 0.9792\n",
            "Epoch 15/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.0597 - acc: 0.9821 - val_loss: 0.0768 - val_acc: 0.9807\n",
            "Epoch 16/20\n",
            "33600/33600 [==============================] - 3s 75us/step - loss: 0.0520 - acc: 0.9833 - val_loss: 0.0736 - val_acc: 0.9786\n",
            "Epoch 17/20\n",
            "33600/33600 [==============================] - 3s 76us/step - loss: 0.0538 - acc: 0.9838 - val_loss: 0.0795 - val_acc: 0.9801\n",
            "Epoch 18/20\n",
            "33600/33600 [==============================] - 2s 74us/step - loss: 0.0480 - acc: 0.9849 - val_loss: 0.0868 - val_acc: 0.9783\n",
            "Epoch 19/20\n",
            "33600/33600 [==============================] - 3s 76us/step - loss: 0.0487 - acc: 0.9847 - val_loss: 0.0827 - val_acc: 0.9800\n",
            "Epoch 20/20\n",
            "33600/33600 [==============================] - 2s 74us/step - loss: 0.0493 - acc: 0.9850 - val_loss: 0.0891 - val_acc: 0.9773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v09GfMKg9ulR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It has a validation score of 97.73% .. So, I'll proceed with this model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COA23CxS-LIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f9ef110c-45f9-410e-c0c1-d17faa33c6d9"
      },
      "source": [
        "test_pred = pd.DataFrame(model4.predict(X_test, batch_size=200))\n",
        "test_pred = pd.DataFrame(test_pred.idxmax(axis = 1))\n",
        "test_pred.index.name = 'ImageId'\n",
        "test_pred = test_pred.rename(columns = {0: 'Label'}).reset_index()\n",
        "test_pred['ImageId'] = test_pred['ImageId'] + 1\n",
        "\n",
        "test_pred.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      1\n",
              "1        2      3\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpWpTkEf-MdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred.to_csv('mnist_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85aTTqSJ-TgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}